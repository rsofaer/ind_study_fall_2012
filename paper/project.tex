\documentclass{article}

\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{lastpage}
\usepackage{epstopdf}
\usepackage{fancyhdr}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\newcommand{\cAuthor}{Raphael Sofaer}
\newcommand{\cTitle}{Implementing Low-Stretch Spanning Trees}
\pagestyle{fancy}
\lhead{\cAuthor}                                                 %
\rhead{\cTitle}  %
%\lfoot{\lastxmark}                                                      %
\cfoot{}                                                                %
\rfoot{Page\ \thepage\ of\ \pageref{LastPage}}                          %
\renewcommand\headrulewidth{0.4pt}                                      %
\renewcommand\footrulewidth{0.4pt}        

\title{\cTitle}
\author{\cAuthor}
\begin{document}
\maketitle

\section*{Abstract}
We implement an algorithm found in `Lower Stretch Spanning Trees', by Spielman et al., and evaluate its stretch performance on a variety of graphs.
\section*{Introduction}
\subsection*{Approximating with Trees}
In the last twenty years, there has been a growing effort to simplify graphs with trees - usually spanning trees - of low `stretch', in order to simplify corresponding Laplacian matrices and thereby rapidly solve linear problems involving symmetric and diagonally dominant matrices.
In 1995, Alon, Karp, Peleg and West\cite{akpw:game} built a zero-sum game in order to investigate the k-server problem\cite{wiki:kserver}, and the payoff in their game was adapted by Spielman et al.\cite{spielman:lower-stretch} into a focused measure of how closely a spanning subtree approximates a graph.

\begin{table}
    \begin{tabular}{|p{3cm}|l|p{5cm}|l|}
    \hline
    Author                      &         Year &                Stretch Metric                                                                              & Average Stretch Upper Bound                             \\ \hline
    Alon, Karp, Peleg, West     & 1995 &           cost(e) = 0 if $e \in T$, otherwise the weight of the unique cycle formed by adding e to T  &                         $exp(O(sqrt(log(n)*log(log(n))))$ \\ \hline
    Elkin, Emek, Spielman, Teng & 2005 & For each edge e=(u,v) in G, $stretch(e) = \frac{TreeDist(u,v)}{length(e)}$                            & O(log(n)*log(n)*log(log(n)))                            \\ \hline
    \end{tabular}
\end{table}
\subsection*{Solving with Approximate Trees}
In parallel to the improving tightness of graph-driven approximations to matrices, the solvers that use these approximations have also been getting faster and in some cases, simpler.
In 1991, P.M. Vaidya presented an unpublished manuscript\cite{vaidya} on constructing preconditioners using approximate subgraphs, which is widely referenced as seminal work\footnote{Unfortunately, we could not find this paper online, only many references to it.}.  This work was extended throughout the 1990s, and by 2004, the combination of recursively building these preconditioners, inexact Chebyshev methods, and more sophisticated graph simplification techniques reduced Vaidya's bound of $$O((dn)^{1.75}log(Îºf(A)/\epsilon))$$ for a SDD system of degree d with non-positive off diagonals to $$mlog^{O(1)}(m)+O(log(cond(A)/\epsilon))(m+n2^{O(\sqrt{lognlog logn})})$$\cite{spielman:nearly-linear-sparse}.
In 2011, Blelloch et al designed an SDD solver meant to work in parallel which approximately solves an SDD system in 
$O(mlog^{O(1)}nlog\frac{1}{\epsilon})$ work and $O(m^{1/3 + \theta}log\frac{1}{\epsilon})$, for any fixed $\theta>0$ (what is this theta?).\\


The latest advance in using approximate trees for solvers is Kelner et al\cite{comb-sdd}, who replace preconditioning with a more direct solution.  They use an electric circuit metaphor, and optimize an electric flow by a stochastic gradient descent-like process within the spanning tree to get an approximate solution to the SDD linear system.  

\subsection*{Implementations}
Since Vaidya proposed these preconditioners, several relevant solvers have been written:\\
From 2001 to 2003, Sivan Toledo, Doron Chen, and Vladimir Rotkin developed TAUCS\cite{taucs}, a library of sparse linear solvers. 
It is implemented in C, and includes a variety of algorithms including Vaidya's preconditioners.\\
Yiannis Koutis wrote CMG\cite{CMG}, a solver which uses multigrid methods and combinatorial preconditioning to solve SDD matrices with non-positive off-diagonal elements.  It is written in C with a MATLAB interface.\\
Zhuo Feng and Zhiyu Zeng have implemented a solver which uses related methods in CUDA for the purpose of power grid analysis.\\
\section*{Our Work}
\subsection*{Vocabulary}
Some of the parts of our low stretch spanning tree algorithm operate on the reciprocals of the weight in a graph, since while a large number in a linear system usually indicates that a row and column are strongly linked, a large weight on a graph edge usually means that edge is less useful.  Spielman et al take $length(e)$ to be $1/weight(e)$, for an edge $e$.  In this paper and in our code, we use Kelner et al's vocabulary for links between graph nodes.  Rather than $weight(e)$, we refer to $resistance(e)$, and let $conductance(e)=1/resistance(e)$.  If `Lower Stretch Spanning Trees' is read as well, this difference should be kept in mind.  

\subsection*{Algorithm}
The LowStretchTree procedure begins with a graph $g$ consisting of edges, vertices, and edge resistances, and a center vertex $x$.
If $g$ is already a tree, it is returned.
The graph $g$ is contracted, meaning each pair of vertices less than a certain distance apart are combined, yielding $g'$. This distance is calculated from the number of nodes in the full graph, distinguished from the number of nodes in subgraphs which are recursively processed.  It is: 
$$l=\frac{((1/(2*log(4/3,num\_vertices(g) + 32)))*radius(g, x))}{num\_vertices(g)}$$\\
The contracted graph $g'$ is then decomposed by the StarDecomp procedure into a central ball and a set of cones, all disjoint, and for each cone, a link between the cone and the central ball.   First the central ball is grown by the BallCut procedure, then the ConeDecomp procedure is applied to the contracted graph $g'$ with the central ball removed.\\
After the contracted graph has been separated into the center and cones, we apply the LowStretchTree procedure to the preimage under contraction of each section.  The resulting trees are combined into a spanning tree using the links from StarDecomp and the spanning tree is returned.

\subsection*{Implementation}
We implemented the algorithm of Spielman et al from `Lower Stretch Spanning Trees' in the Julia language\cite{julia:website}, a recent language combining dynamic typing with just-in-time compilation via LLVM to get good speed on easily written code.  We chose Julia for the ease of programming it gives without sacrificing good speed on custom datasets and interfaces.  We use the Julia Graphs library\cite{julia:graphs}, which is a port of the Boost Graph Library.  Our algorithm operates on an incidence list type defined in weightedinclist.jl.  The implementation is not aggressively optimized for good running time, and we do not consider the running time to be representative of what a lower level or highly parallelized implementation could reach.  However, the stretch we calculate can be used to estimate how well preconditioners or solvers which use low strech spanning trees might work on these types of graphs.\\

We use an incidence list data structure for our code, although the algorithm will operate on any graph data structure that allows iteration through vertices and neighbors.  Vertices are integers, edges are pairs of integer vertices with an associated integer index, the vertex list is a vector of integers, and the incidence lists are vectors of edges.  The resistances of edges are stored in a separate vector in the graph instance.  These definitions and functions which are closely tied to the data structure are in weightedinclist.jl.\\

To represent subgraphs, we combine a graph with a pair of Set data structures, one to mark which edges are included and one to mark which vertices are included.  This structure and its associated functions are in subgraph.jl.\\	
To explain the implementation of the algorithm, we will consider step by step a call to LowStretchTree:
\begin{verbatim}
	t = LowStretchTree(g, center_vertex)
\end{verbatim}
We begin by returning $g$ if it is a tree.  Then, the first step of the $LowStretchTree$ procedure is to contract the input graph so we can decompose a simpler graph and avoid looking through all the vertices at each iteration.  To do this, we need to know the radius of the graph around our center vertex, which is the maximum distance from the center vertex to any other vertex.  This is accomplished through the $radius$ function, which uses dijkstra's algorithm to find the farthest vertex.  With that information we calculate $l$.
$$l=\frac{((1/(2*log(4/3,num\_vertices(g) + 32)))*radius(g, x))}{num\_vertices(g)}$$
 Then we can contract the graph using the $contract$ function to get a simpler approximate version of $g$, which we will call $c\_g$.
\begin{verbatim}
	contracted_g, image_map, preimage_arrays = contract(g,l)
\end{verbatim}
$contract$ begins by using a disjoint set data structure provided by the Julia DataStructures package to determine the groups of vertices in $g$ which correspond to single vertices in $c\_g$.  For each edge in $g$, if the edge's resistance is less than $l$, the minimum edge length, we combine the sets corresponding to $source(e)$ and $target(e)$.  After this, we have disjoint sets of vertices in $g$, each corresponding to a single vertex in $c\_g$.  For the decomposition step later on, we will need to map back and forth from the contracted vertices to the original vertices, so we create $image\_map$, a map from vertices in $g$ to corresponding image vertices in $c\_g$, and $preimage\_arrays$, a vector of vectors of preimages of vertices in $c\_g$.  For each vertex $v$ in $g$, we mark its image in $image\_map$, and add it to the correct vector in $preimage\_arrays$.  Then $c\_g$, $image\_map$, and $preimage\_arrays$ are returned to $LowStretchTree$.\\

Once we have the contracted graph, we pass it to $StarDecomp$ to separate it into parts to be recursively processed.
\begin{verbatim}
	result = StarDecomp(contracted_g, image_map[center_vertex], 1/3, beta)
	c_center_ball, c_vertex_sets, c_cone_side_links, c_core_side_links = result
\end{verbatim}
$StarDecomp$ begins by growing a ball from the image under contraction of the center vertex.  This happens in the $BallCut$ procedure. 
\begin{verbatim}
rho = radius(center_vertex, c_g)
while cost(boundary(c_g, cur_ball), c_g) > ((vol(cur_ball) + 1)/((1-2*delta)*rho))*log2(num_edges(c_g)+1)
   #Expand the ball to include the next closest vertex.
   ...
end
\end{verbatim}
Then, we take the part of $c\_g$ not included in the center ball but bordering on the center ball, which we call the center shell, and pass them to $ConeCut$.  $\epsilon$ and $\rho$ depend on the size of the graph.
\begin{verbatim}
	cones, cone_side_terminals = ConeDecomp(cored_g, central_shell, epsilon*rho/2)
\end{verbatim}
ConeCut begins by using $central\_shell$ as a queue $S$.  While there are vertices in $S$, take one vertex $v$ out, and build a cone centered on that vertex.  The cone is built in $ConeCut$ and is defined with the following invariant.  If the shortest path from $center\_vertex$ to $v$ intersects $build\_cone(g, S, l, center)$, v is in the cone.  Here $l$ depends on the size of the graph.
Once we have the cones, $StarDecomp$ finds the best link from each cone to the central ball, then returns them to $LowStretchTree$.  $LowStretchTree$ then passes each section returned from $StarDecomp$ to $process\_star\_section$.  Since each section is processed independently, this may be a good place to parallelize the algorithm. 
\begin{verbatim}
	f = (a, b, c) -> process_star_section(a, b, c,g,  preimage_arrays, original_num_vertices)
	trees_and_links = map(f, c_vertex_sets, c_cone_side_links, c_core_side_links)
\end{verbatim}
$process\_star\_section$ finds the preimage of each cone and the link from the cone to the central ball, then passes the cone to $LowStretchTree$.   It then returns the subtrees and their links to the central ball to $LowStretchTree$, which combines them with the center and returns the full tree.
\begin{verbatim}
	for (tree, link) in trees_and_links
		result = combine(tree, result)
		push!(cone_core_links, link)
	end

	result = add_edges(result, cone_core_links)

	return result
\end{verbatim}
Here $result$ is a low-stretch spanning tree of $g$.

\section*{Results}
\subsection*{Test Data}
We tested our algorithm on several datasets.  First, we create a set of uniform random graphs at various sizes and densities, generated by the Julia Graphs library's erdos\_renyi\_graph function.\\
Second, we take a set of small world graphs at several sizes, neighborhood sizes, and rewiring chances.  These are generated by the Julia Graphs library's watts\_strogatz\_graph function.\\
Third, we take several graphs from Feifei Li et al's collection of spatial databases\cite{feifei-data}, created for their project on spatial databases and trip planning\cite{feifei-paper}.  While the spatial characteristics of these graphs are not relevant to this project, taking edge resistance to be L2 length and using latitude and longitude for layout makes the generated spanning trees easy to evaluate at a glance even for large graphs, a great help to our debugging.  We use their graphs of the California, Oldenburg, San Francisco, and North America road networks.  These are sparse, since they are planar or close to planar.  We removed duplicate edges before applying our algorithm.
\subsection*{Calculating Stretch}
Spielman et al. give the definitions for stretch and average stretch in their paper as follows:
$$stretch(graph, tree, u, v) = \frac{distance(tree, u, v)}{distance(graph, u, v)}$$
$$ave\_stretch(graph, tree) = \frac{1}{num\_edges(g)}*\sum\limits_{(u,v)\in edges(g)}stretch(graph, tree, u, v)$$
In order to calculate average stretch, for each edge $(u,v)$ in $g$, we need to find the distance from $u$ to $v$ in $t$.  Since t is a tree, this can be done in $O(n^2)$ time with DFS.
\subsection*{Stretch Levels}
Compare stretch on graphs to MST stretch and asympstotic bound given by S\&T.
\subsection*{Stability of stretch}
How does the stretch change with different starting centers, as S\&T give no recommendation on selecting a central vertex?
\bibliography{project}{}
\bibliographystyle{ieeetr}
\end{document}